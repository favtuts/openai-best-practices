import os
import re
import google.generativeai as genai

from PIL import Image
import streamlit as st

from qa_robot.extract_texts_from_file import extract_text_from_file
from qa_robot.create_prompt import create_prompt

from qa_robot.constants import *

# Configuration Constants
TEMPERATURE_PARAMS = [0.1,0.5, 0.7] #[0.1, 0.3] # [0.5, 0.7]
MAX_INPUT_TOKENS = 2000
MIN_INPUT_TOKENS = 1000
MAX_CALL_API_BY_PROMPT = 2
SLEEP_TIME_MIN = 0.1
SLEEP_TIME_MAX = 1.0


# Gemini AI Configuration
API_KEY = 'XXXX'

genai.configure(api_key=API_KEY, transport='rest')
text_model = genai.GenerativeModel('gemini-pro')
vision_model = genai.GenerativeModel('gemini-pro-vision')

def generate_text(prompt, temperature):
    output_text = ''
    response = None
    generation_config = genai.GenerationConfig(
    temperature=temperature,
    top_p=1.0,
    top_k=32,
    candidate_count=1
    )

    response = text_model.generate_content(prompt, generation_config = generation_config)
    output_text = extract_text_from_response(response)
    
    return output_text

def remove_special_characters(text):
    text = text.replace('**', '')
    # Normalize line endings and remove carriage returns
    text = text.replace('\r\n', '\n').replace('\r', '')
    text = text.replace('{', '\n\n')
    text = text.replace('}', '\n\n')
    text = text.replace('"question":', '\n\n"question":')
    text = text.replace('Câu hỏi', '"question":')
    text = text.replace('Trả lời:', '"answer":')

    # Regular expression pattern to match any number followed by a colon
    pattern = r'\d+:'
    # Replace found patterns with an empty string
    text = re.sub(pattern, '', text)

    return text

def reset_prompt():
    # To demand gemini to forget all previous conversations
    text_model.generate_content('Forget all previous conversations.')

def generate_text_from_text_file(file_path, file_type, instruction, target_language):
    # Extract text from the file based on its type
    text_page_list = extract_text_from_file(file_path, file_type)
    
    # Create a placeholder
    progress_bar_placeholder = st.empty()
    progress_text_placeholder = st.empty()

    # Join the text into a single string
    text_full = ''
    for idx, text in text_page_list:
        text_full += text + ' '

    # Split text
    text_list = split_text_into_chunks(text_full, chunk_size=MAX_INPUT_TOKENS)

    output_text_full = ''
    prompt = create_prompt(instruction, target_language)
        
    sleep_time = SLEEP_TIME_MIN
    total_chunks = len(text_list)
    try:
        for temperature in TEMPERATURE_PARAMS:
            chunk_counter = 0
            temp_text = ''
            reset_prompt()
            for i, text in enumerate(text_list):
                output_text = ''
                # prompt = [prompt, text]
                prompt = prompt +  text
                output_text = generate_text(prompt, temperature)
                output_text = remove_special_characters(output_text)

                output_text_full += output_text

                temp_text += output_text
                print(temp_text)

                # Calculate the percentage completed
                percent_complete = int((chunk_counter + 1) / total_chunks * 100)
                # Update the progress bar
                progress_bar_placeholder.progress(percent_complete)
                # Update the percentage text
                progress_text_placeholder.text(f'Temperature: {temperature:.1f}  Progress: {percent_complete/100:.0%}')
                
                chunk_counter += 1

            sleep_time += sleep_time * 0.5
            progress_bar_placeholder = st.empty()
            progress_text_placeholder = st.empty()

    except Exception as e:
        print('Server overloaded')
        print(e)
        st.warning('Server overloaded. Cannot generate all Q&A. Please try again later!')

    return output_text_full, text_page_list
    

def get_basename(path):
    """Extract the base name without extension from a file path."""
    return os.path.splitext(os.path.basename(path))[0]

def split_text_into_chunks(text, chunk_size=MAX_INPUT_TOKENS):
    """Split a text into chunks based on a specified chunk size, breaking at sentence ends."""
    words = text.split()
    chunks = []
    current_chunk = []
    
    for word in words:
        current_chunk.append(word)
        if word.endswith('.'):
            if len(current_chunk) >= chunk_size:
                chunks.append(' '.join(current_chunk))
                current_chunk = []
    
    if current_chunk:
        chunks.append(' '.join(current_chunk))
    
    return chunks



def clean_generated_text(text):
    """Clean unwanted characters from text generated by Gemini."""
    replacements = {
        '```': '', '"': '', '[': '', ']': '',
        '\u201d': '', '\u201c': '', '\u2019': '',
        '\u2013': '', '\n': ' '
    }
    for old, new in replacements.items():
        text = text.replace(old, new)
    return text

def extract_text_from_response(response):
    """Extract and concatenate text from a Gemini response."""
    all_texts = ''
    for candidate in response.candidates:
        candidate_texts = [part.text for part in candidate.content.parts]
        all_texts += '. '.join(candidate_texts) + '. '
    
    return all_texts.strip()

